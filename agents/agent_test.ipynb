{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a990fc4b",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "To run the tests and main components of this project, make sure you have the following packages installed in your environment:\n",
    "\n",
    "```bash\n",
    "pip install \\\n",
    "    asyncio \\\n",
    "    typing-extensions \\\n",
    "    pydantic \\\n",
    "    autogen-core \\\n",
    "    autogen-agentchat \\\n",
    "    autogen-ext[ollama]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70cacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Literal\n",
    "from autogen_core.models import UserMessage, ModelInfo\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from pydantic import BaseModel\n",
    "import time\n",
    "\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734aed23",
   "metadata": {},
   "source": [
    "# Basic example\n",
    "This example shows how to create an agent with autogen API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59385534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_based  = \"hf.co/stepii/salamandra-7b-instruct-tools-GGUF:Q8_0\"\n",
    "model_client = OllamaChatCompletionClient(\n",
    "    model = model_based,\n",
    "    model_info=ModelInfo(vision=False, function_calling=True, json_output=False, family=\"unknown\", structured_output=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2950ee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(id='3e6c87f6-a324-4297-b3e6-77fbc5434a34', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 31, 7, 41, 59, 948437, tzinfo=datetime.timezone.utc), content='Name two cities in North America.', type='TextMessage'), TextMessage(id='ad79ff86-ad84-4f6d-b1e0-245a86ff64a1', source='assistant', models_usage=RequestUsage(prompt_tokens=47, completion_tokens=13), metadata={}, created_at=datetime.datetime(2025, 7, 31, 7, 42, 43, 628208, tzinfo=datetime.timezone.utc), content='Two cities in North America are New York City and Toronto.', type='TextMessage')] stop_reason=None\n"
     ]
    }
   ],
   "source": [
    "async def main() -> None:\n",
    "    agent = AssistantAgent(name=\"assistant\", model_client=model_client)\n",
    "    result = await agent.run(task=\"Name two cities in North America.\")\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29b22b",
   "metadata": {},
   "source": [
    "# Agent stream example\n",
    "This example shows as how to create an agent capable to generate answers in real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4869d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='14f3dd5c-062b-4511-82c2-666fc2f5139b' source='user' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 43, 466117, tzinfo=datetime.timezone.utc) content='Name two cities in North America.' type='TextMessage'\n",
      "id='c4f4286d-f5ef-4ec0-bb2b-a2448df53234' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 43, 939848, tzinfo=datetime.timezone.utc) content='S' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='5d3d728a-5dfc-4e90-af59-f138301c7858' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 44, 294682, tzinfo=datetime.timezone.utc) content='ure' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='13fa429a-176c-4a3f-a1a3-5cb2e00ec6b2' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 44, 745478, tzinfo=datetime.timezone.utc) content=',' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='b4b067ac-1ddb-405f-9e7f-8d878f3fb7d4' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 45, 121206, tzinfo=datetime.timezone.utc) content=' here' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='5620a5b6-0df0-4932-ab9d-16f76c33e726' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 45, 551361, tzinfo=datetime.timezone.utc) content=' are' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='e1f80e02-1170-404e-9c2f-e499fb1c1ef0' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 46, 87614, tzinfo=datetime.timezone.utc) content=' two' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='fb8a37a1-6ba6-45f8-b2a7-912b1288fffe' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 46, 691275, tzinfo=datetime.timezone.utc) content=' cities' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='0f118916-6480-4e5a-87dd-c5148de990c3' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 47, 165399, tzinfo=datetime.timezone.utc) content=' in' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='8eeb5b40-c46a-4b4d-acad-5b5b79493f61' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 47, 666515, tzinfo=datetime.timezone.utc) content=' North' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='517d885b-c275-4e61-a6c6-46455ba47785' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 48, 200146, tzinfo=datetime.timezone.utc) content=' America' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='159f8609-ee32-44b8-9862-41f03dc63729' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 48, 789954, tzinfo=datetime.timezone.utc) content=':' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='62b98a32-cb67-4a56-8e88-6ce86e331dcb' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 49, 251539, tzinfo=datetime.timezone.utc) content='\\n\\n' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='3d7abcb1-d7a2-4427-a0fb-8dac81582354' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 49, 738454, tzinfo=datetime.timezone.utc) content='1' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='5bc1e680-835b-4256-a979-0fccae195b80' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 50, 172227, tzinfo=datetime.timezone.utc) content='.' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='56e1c0da-12ae-4e3c-8e88-f21cd1bf3210' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 50, 575258, tzinfo=datetime.timezone.utc) content=' New' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='1abd863b-884f-482e-bfc6-7142aab3e0dc' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 50, 989659, tzinfo=datetime.timezone.utc) content=' York' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='0f01dbf4-2710-4a13-97e4-479be18adfea' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 51, 464457, tzinfo=datetime.timezone.utc) content=' City' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='dbe4386d-3bc0-4b52-97cb-8c43705e4d40' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 51, 915512, tzinfo=datetime.timezone.utc) content=',' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='f35a88c5-abf8-40d4-85e3-7d629b80ef87' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 52, 392957, tzinfo=datetime.timezone.utc) content=' USA' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='a224a545-a50d-4ebe-a7f8-5257e6d72c7d' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 52, 846204, tzinfo=datetime.timezone.utc) content='\\n' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='a3a7d3e9-7682-4ce3-84af-d153cc7ca514' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 53, 311077, tzinfo=datetime.timezone.utc) content='2' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='dd38ce47-4871-463a-917a-28db4782656e' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 53, 769505, tzinfo=datetime.timezone.utc) content='.' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='d487b7b1-ab22-4e09-a7e2-1f7f77895820' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 54, 195020, tzinfo=datetime.timezone.utc) content=' Toronto' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='14331f2f-635c-4cc1-95c0-504fb9cd8e3e' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 54, 618913, tzinfo=datetime.timezone.utc) content=',' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='32f0073b-bc39-439e-997d-0d196e7361ee' source='assistant' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 55, 50037, tzinfo=datetime.timezone.utc) content=' Canada' full_message_id='e1c4e943-38bb-42bc-8a2d-734e1e881207' type='ModelClientStreamingChunkEvent'\n",
      "id='e1c4e943-38bb-42bc-8a2d-734e1e881207' source='assistant' models_usage=RequestUsage(prompt_tokens=47, completion_tokens=26) metadata={} created_at=datetime.datetime(2025, 7, 30, 8, 18, 55, 575485, tzinfo=datetime.timezone.utc) content='Sure, here are two cities in North America:\\n\\n1. New York City, USA\\n2. Toronto, Canada' type='TextMessage'\n",
      "messages=[TextMessage(id='14f3dd5c-062b-4511-82c2-666fc2f5139b', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 30, 8, 18, 43, 466117, tzinfo=datetime.timezone.utc), content='Name two cities in North America.', type='TextMessage'), TextMessage(id='e1c4e943-38bb-42bc-8a2d-734e1e881207', source='assistant', models_usage=RequestUsage(prompt_tokens=47, completion_tokens=26), metadata={}, created_at=datetime.datetime(2025, 7, 30, 8, 18, 55, 575485, tzinfo=datetime.timezone.utc), content='Sure, here are two cities in North America:\\n\\n1. New York City, USA\\n2. Toronto, Canada', type='TextMessage')] stop_reason=None\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    agent = AssistantAgent(\n",
    "            name=\"assistant\",\n",
    "            model_client=model_client,\n",
    "            model_client_stream=True,\n",
    "        )\n",
    "\n",
    "    stream = agent.run_stream(task=\"Name two cities in North America.\")\n",
    "    async for message in stream:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c91b5",
   "metadata": {},
   "source": [
    "# Example tool agents\n",
    "This example shows as how to create agents that can generate responses with tools. Below you will see all the basic functions that we will be using for the rest of the basic testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30f9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def sum_function(x: int, y: int) -> str:\n",
    "    \"\"\"This function grabs two numerical values in the context and aggregate them\"\"\"\n",
    "    return(f\"{x} + {y} = {x+y}\")\n",
    "\n",
    "async def product_function(x: int, y: int) -> str:\n",
    "    \"\"\"This function grabs two numerical values in the context and multiply them\"\"\"\n",
    "    return(f\"{x} * {y} = {x*y}\")\n",
    "\n",
    "async def plus_counter() -> str:\n",
    "    \"\"\"This function returns a counter plus one\"\"\"\n",
    "    global counter\n",
    "    counter+=1\n",
    "    return(f\"Counter incremented to: {counter}\")\n",
    "\n",
    "async def get_counter(counter: int) -> str:\n",
    "    return(f\"The current value of the counter is {counter}\")\n",
    "\n",
    "async def is_pair(value: int) -> str:\n",
    "    return \"Pair\" if value % 2 == 0 else \"Odd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2391601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is 2 + 2?\n",
      "---------- ToolCallRequestEvent (assistant) ----------\n",
      "[FunctionCall(id='0', arguments='{\"x\": \"2\", \"y\": \"2\"}', name='sum_function')]\n",
      "---------- ToolCallExecutionEvent (assistant) ----------\n",
      "[FunctionExecutionResult(content='2 + 2 = 4', name='sum_function', call_id='0', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (assistant) ----------\n",
      "2 + 2 = 4\n",
      "---------- TextMessage (user) ----------\n",
      "How much is  32 times 2?\n",
      "---------- ToolCallRequestEvent (assistant) ----------\n",
      "[FunctionCall(id='1', arguments='{\"x\": \"32\", \"y\": \"2\"}', name='product_function')]\n",
      "---------- ToolCallExecutionEvent (assistant) ----------\n",
      "[FunctionExecutionResult(content='32 * 2 = 64', name='product_function', call_id='1', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (assistant) ----------\n",
      "32 * 2 = 64\n"
     ]
    }
   ],
   "source": [
    "async def main():    \n",
    "    agent = AssistantAgent(\n",
    "        name=\"assistant\", \n",
    "        model_client=model_client, \n",
    "        tools=[sum_function, product_function], \n",
    "    )\n",
    "\n",
    "    await Console(agent.run_stream(task=\"What is 2 + 2?\"))\n",
    "    await Console(agent.run_stream(task=\"How much is  32 times 2?\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d7e6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e0d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Can you increment the counter by 3 and show me the final result?\n",
      "---------- ThoughtEvent (assistant) ----------\n",
      "\", \"parameters\": {\"counter\": \"3\"}}\n",
      "---------- ToolCallRequestEvent (assistant) ----------\n",
      "[FunctionCall(id='0', arguments='{}', name='plus_counter')]\n",
      "---------- ToolCallExecutionEvent (assistant) ----------\n",
      "[FunctionExecutionResult(content='Counter incremented to: 1', name='plus_counter', call_id='0', is_error=False)]\n",
      "---------- TextMessage (assistant) ----------\n",
      " TERMINATE\n",
      "---------- TextMessage (user) ----------\n",
      "Can you increment the counter by 5 and show me the final result?\n",
      "---------- ToolCallRequestEvent (assistant) ----------\n",
      "[FunctionCall(id='1', arguments='{\"counter\": 6}', name='get_counter')]\n",
      "---------- ToolCallExecutionEvent (assistant) ----------\n",
      "[FunctionExecutionResult(content='The current value of the counter is 6', name='get_counter', call_id='1', is_error=False)]\n",
      "---------- TextMessage (assistant) ----------\n",
      " TERMINATE\n",
      "---------- TextMessage (user) ----------\n",
      "Can you increment the counter by 6 and show me the final result?\n",
      "---------- ToolCallRequestEvent (assistant) ----------\n",
      "[FunctionCall(id='2', arguments='{\"counter\": 7}', name='get_counter')]\n",
      "---------- ToolCallExecutionEvent (assistant) ----------\n",
      "[FunctionExecutionResult(content='The current value of the counter is 7', name='get_counter', call_id='2', is_error=False)]\n",
      "---------- TextMessage (assistant) ----------\n",
      " TERMINATE\n"
     ]
    }
   ],
   "source": [
    "async def main():    \n",
    "    agent = AssistantAgent(\n",
    "        name=\"assistant\", \n",
    "        model_client=model_client, \n",
    "        tools=[get_counter, plus_counter], \n",
    "        max_tool_iterations = 5,\n",
    "    )\n",
    "\n",
    "    await Console(agent.run_stream(task=\"Can you increment the counter by 3 and show me the final result?\"))\n",
    "    await Console(agent.run_stream(task=\"Can you increment the counter by 5 and show me the final result?\"))\n",
    "    await Console(agent.run_stream(task=\"Can you increment the counter by 6 and show me the final result?\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c5bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Is 2 an even number?\n",
      "---------- StructuredMessage[AgentResponse] (assistant) ----------\n",
      "{\"message\":\"{'name': 'is_pair', 'parameters': {'value': 2}}\",\"response\":\"Pair\"}\n",
      "---------- TextMessage (user) ----------\n",
      "Is 3 an odd number?\n",
      "---------- StructuredMessage[AgentResponse] (assistant) ----------\n",
      "{\"message\":\"{'name': 'is_pair', 'parameters': {'value': 3}}\",\"response\":\"Odd\"}\n"
     ]
    }
   ],
   "source": [
    "class AgentResponse(BaseModel):\n",
    "    message: str\n",
    "    response: Literal[\"Pair\", \"Odd\"]\n",
    "\n",
    "# This test doesn't work correctly if we use aina instead use another model like llama3.1:8b that also support tools\n",
    "model_based  = \"llama3.1:8b\"\n",
    "model_client = OllamaChatCompletionClient(\n",
    "    model = model_based,\n",
    "    model_info=ModelInfo(vision=False, function_calling=True, json_output=False, family=\"unknown\", structured_output=True),\n",
    ")\n",
    "async def main():\n",
    "    tool = FunctionTool(is_pair, description=\"Pair Analysis\", strict=True)\n",
    "    agent = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        model_client=model_client, \n",
    "        tools=[tool], \n",
    "        system_message=\"You are a system capable to detect if a number is pair or odd by a given input.\",\n",
    "        output_content_type=AgentResponse,\n",
    "    )\n",
    "\n",
    "    await Console(agent.run_stream(task=\"Is 2 an even number?\")) \n",
    "    await Console(agent.run_stream(task=\"Is 3 an odd number?\")) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5ad0e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
